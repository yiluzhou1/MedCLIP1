{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1cbb943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "from medclip import MedCLIPModel, MedCLIPVisionModelViT\n",
    "from medclip import MedCLIPProcessor\n",
    "from medclip import PromptClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c500a330",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yzhou\\AppData\\Local\\miniconda3\\envs\\test\\lib\\site-packages\\transformers\\models\\clip\\feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at microsoft/swin-tiny-patch4-window7-224 were not used when initializing SwinModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing SwinModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing SwinModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PromptClassifier(\n",
       "  (model): MedCLIPModel(\n",
       "    (vision_model): MedCLIPVisionModelViT(\n",
       "      (model): SwinModel(\n",
       "        (embeddings): SwinEmbeddings(\n",
       "          (patch_embeddings): SwinPatchEmbeddings(\n",
       "            (projection): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "          )\n",
       "          (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (encoder): SwinEncoder(\n",
       "          (layers): ModuleList(\n",
       "            (0): SwinStage(\n",
       "              (blocks): ModuleList(\n",
       "                (0-1): 2 x SwinLayer(\n",
       "                  (layernorm_before): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attention): SwinAttention(\n",
       "                    (self): SwinSelfAttention(\n",
       "                      (query): Linear(in_features=96, out_features=96, bias=True)\n",
       "                      (key): Linear(in_features=96, out_features=96, bias=True)\n",
       "                      (value): Linear(in_features=96, out_features=96, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): SwinSelfOutput(\n",
       "                      (dense): Linear(in_features=96, out_features=96, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): SwinDropPath(p=0.1)\n",
       "                  (layernorm_after): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "                  (intermediate): SwinIntermediate(\n",
       "                    (dense): Linear(in_features=96, out_features=384, bias=True)\n",
       "                    (intermediate_act_fn): GELUActivation()\n",
       "                  )\n",
       "                  (output): SwinOutput(\n",
       "                    (dense): Linear(in_features=384, out_features=96, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (downsample): SwinPatchMerging(\n",
       "                (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
       "                (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (1): SwinStage(\n",
       "              (blocks): ModuleList(\n",
       "                (0-1): 2 x SwinLayer(\n",
       "                  (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attention): SwinAttention(\n",
       "                    (self): SwinSelfAttention(\n",
       "                      (query): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (key): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (value): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): SwinSelfOutput(\n",
       "                      (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): SwinDropPath(p=0.1)\n",
       "                  (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                  (intermediate): SwinIntermediate(\n",
       "                    (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "                    (intermediate_act_fn): GELUActivation()\n",
       "                  )\n",
       "                  (output): SwinOutput(\n",
       "                    (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (downsample): SwinPatchMerging(\n",
       "                (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "                (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (2): SwinStage(\n",
       "              (blocks): ModuleList(\n",
       "                (0-5): 6 x SwinLayer(\n",
       "                  (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attention): SwinAttention(\n",
       "                    (self): SwinSelfAttention(\n",
       "                      (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): SwinSelfOutput(\n",
       "                      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): SwinDropPath(p=0.1)\n",
       "                  (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (intermediate): SwinIntermediate(\n",
       "                    (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                    (intermediate_act_fn): GELUActivation()\n",
       "                  )\n",
       "                  (output): SwinOutput(\n",
       "                    (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (downsample): SwinPatchMerging(\n",
       "                (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "                (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (3): SwinStage(\n",
       "              (blocks): ModuleList(\n",
       "                (0-1): 2 x SwinLayer(\n",
       "                  (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (attention): SwinAttention(\n",
       "                    (self): SwinSelfAttention(\n",
       "                      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): SwinSelfOutput(\n",
       "                      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): SwinDropPath(p=0.1)\n",
       "                  (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (intermediate): SwinIntermediate(\n",
       "                    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                    (intermediate_act_fn): GELUActivation()\n",
       "                  )\n",
       "                  (output): SwinOutput(\n",
       "                    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (pooler): AdaptiveAvgPool1d(output_size=1)\n",
       "      )\n",
       "      (projection_head): Linear(in_features=768, out_features=512, bias=False)\n",
       "    )\n",
       "    (text_model): MedCLIPTextModel(\n",
       "      (model): BertModel(\n",
       "        (embeddings): BertEmbeddings(\n",
       "          (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (token_type_embeddings): Embedding(2, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): BertEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (pooler): BertPooler(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (activation): Tanh()\n",
       "        )\n",
       "      )\n",
       "      (projection_head): Linear(in_features=768, out_features=512, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init models\n",
    "processor = MedCLIPProcessor()\n",
    "model = MedCLIPModel(vision_cls=MedCLIPVisionModelViT) #, checkpoint='./data/MedCLIP/checkpoints/vision_text_pretrain/25000'\n",
    "clf = PromptClassifier(model, ensemble=True)\n",
    "clf.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3bc5dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 10 num of prompts for Atelectasis from total 210\n",
      "sample 10 num of prompts for Cardiomegaly from total 15\n",
      "sample 10 num of prompts for Consolidation from total 192\n",
      "sample 10 num of prompts for Edema from total 18\n",
      "sample 10 num of prompts for Pleural Effusion from total 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yzhou\\AppData\\Local\\miniconda3\\envs\\test\\lib\\site-packages\\transformers\\image_transforms.py:382: RuntimeWarning: divide by zero encountered in divide\n",
      "  image = (image - mean) / std\n",
      "c:\\Users\\yzhou\\AppData\\Local\\miniconda3\\envs\\test\\lib\\site-packages\\transformers\\image_transforms.py:382: RuntimeWarning: invalid value encountered in divide\n",
      "  image = (image - mean) / std\n"
     ]
    }
   ],
   "source": [
    "# prepare input image\n",
    "from PIL import Image\n",
    "image = Image.open('./example_data/view1_frontal.jpg')\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "# prepare input prompt texts\n",
    "from medclip.prompts import generate_chexpert_class_prompts, process_class_prompts\n",
    "\n",
    "cls_prompts = process_class_prompts(generate_chexpert_class_prompts(n=10))\n",
    "inputs['prompt_inputs'] = cls_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ecab86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pixel_values': tensor([[[[nan, nan, nan],\n",
      "          [nan, nan, nan],\n",
      "          [nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan],\n",
      "          [nan, nan, nan],\n",
      "          [nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan],\n",
      "          [nan, nan, nan],\n",
      "          [nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan],\n",
      "          [nan, nan, nan],\n",
      "          [nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan],\n",
      "          [nan, nan, nan],\n",
      "          [nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan],\n",
      "          [nan, nan, nan],\n",
      "          [nan, nan, nan]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[nan, nan, nan],\n",
      "          [nan, nan, nan],\n",
      "          [nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan],\n",
      "          [nan, nan, nan],\n",
      "          [nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan],\n",
      "          [nan, nan, nan],\n",
      "          [nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan],\n",
      "          [nan, nan, nan],\n",
      "          [nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan],\n",
      "          [nan, nan, nan],\n",
      "          [nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan],\n",
      "          [nan, nan, nan],\n",
      "          [nan, nan, nan]]]], dtype=torch.float64), 'prompt_inputs': defaultdict(None, {'Atelectasis': {'input_ids': tensor([[  101, 16516, 16531,  8009,  1197,  8756, 18465, 14229,  1120,  1103,\n",
      "          1286,  2211, 25163,   102,     0],\n",
      "        [  101, 10298, 16516, 16531,  8009,  1197,  8756, 18465, 14229,  1120,\n",
      "          1103,  2286, 13093,  4834,   102],\n",
      "        [  101, 10298, 25399,  8756, 18465, 14229,  1120,  1103, 13093,  7616,\n",
      "           102,     0,     0,     0,     0],\n",
      "        [  101, 10496,  4841,  2217, 14294,  1348,  8756, 18465, 14229,  1120,\n",
      "          1103, 20557, 13093,  7616,   102],\n",
      "        [  101, 10298,  1467, 10318,  8756, 18465, 14229,  1120,  1103, 20557,\n",
      "         13093,  7616,   102,     0,     0],\n",
      "        [  101, 16516, 16531,  8009,  1197,  8756, 18465, 14229,  1120,  1103,\n",
      "          1268, 13093,  2259,   102,     0],\n",
      "        [  101,  1231,  8005, 10542, 12571,  8756, 18465, 14229,  1120,  1103,\n",
      "          1268,  2211, 25163,   102,     0],\n",
      "        [  101, 16516, 16531,  8009,  1197,  8756, 18465, 14229,  1120,  1103,\n",
      "          1286, 13093,  2259,   102,     0],\n",
      "        [  101, 25399,  8756, 18465, 14229,  1120,  1103,  1286, 13093,  4834,\n",
      "           102,     0,     0,     0,     0],\n",
      "        [  101, 10298, 25399,  8756, 18465, 14229,  1120,  1103,  1268, 13093,\n",
      "          4834,   102,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])}, 'Cardiomegaly': {'input_ids': tensor([[  101, 15970,  3621,  2660,  3263,  6997,  1183,  1114,  3289,  3105,\n",
      "         25163,  5956,   102,     0],\n",
      "        [  101, 15970,  5199,  3621,  2660,  3263,  6997,  1183,   102,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101, 17688, 27316,  2060,  1110, 21461, 12089,   102,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  3621,  2660,  3263,  6997,  1183, 16684,   102,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101, 15139,  2458,  1104,  1103,  2229, 17798, 10496,  3621,  2660,\n",
      "          3263,  6997,  1183,   102],\n",
      "        [  101,  1762,  2060,  2606,  1120, 21461, 12089,   102,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  1762,  2060,  1110,  3070,  2568, 12089,   102,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101, 15139,  2458,  1104,  1103,  2229, 17798,  6111,  3621,  2660,\n",
      "          3263,  6997,  1183,   102],\n",
      "        [  101, 21461,  3289, 17688, 27316,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  3621,  2660,  3263,  6997,  1183,  1134,  1110, 16684,   102,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])}, 'Consolidation': {'input_ids': tensor([[  101,  2569,  1231,  2941,  5552, 20994,  1120,  1103,  1268,  1146,\n",
      "         11292, 25163,   102,     0],\n",
      "        [  101,  4725, 20557, 20994,  1120,  1103,  3105, 13093,  4834,   102,\n",
      "             0,     0,     0,     0],\n",
      "        [  101, 12647, 19776,  2093,  1104, 10085,  1183, 20994,  1120,  1103,\n",
      "          2211, 13093,  4834,   102],\n",
      "        [  101,  2569,  1231,  2941,  5552, 20994,  1120,  1103,  1286,  3105,\n",
      "         25163,   102,     0,     0],\n",
      "        [  101,  2569, 10085,  1183, 20994,  1120,  1103,  1286,  3105, 25163,\n",
      "           102,     0,     0,     0],\n",
      "        [  101,  2569, 20557, 20994,  1120,  1103,  1268, 13093,  2259,   102,\n",
      "             0,     0,     0,     0],\n",
      "        [  101, 15692, 12204, 20994,  1120,  1103,  1286,  2211, 25163,   102,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2569,  1231,  2941,  5552, 20994,  1120,  1103,  3105, 13093,\n",
      "          4834,   102,     0,     0],\n",
      "        [  101,  2569,  7597, 20994,  1120,  1103,  1286,  2211, 25163,   102,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2569, 20557, 20994,  1120,  1103,  1268,  1146, 11292, 25163,\n",
      "           102,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])}, 'Edema': {'input_ids': tensor([[  101,  8332,  9455,  2050, 17030,  1348,  5048, 14494,   102,     0,\n",
      "             0],\n",
      "        [  101,  8331,  1107,  8332,  9455,  2050, 17030,  1348,  5048, 14494,\n",
      "           102],\n",
      "        [  101, 10496,  8332,  9455,  2050, 17030,  1348,  5048, 14494,   102,\n",
      "             0],\n",
      "        [  101, 10558, 26600,  9455,  2050, 17030,  1348,  5048, 14494,   102,\n",
      "             0],\n",
      "        [  101,  8828,  8332,  9455,  2050, 17030,  1348,  5048, 14494,   102,\n",
      "             0],\n",
      "        [  101,  3073, 22398,  3452, 26600,  5048, 14494,   102,     0,     0,\n",
      "             0],\n",
      "        [  101, 10558,  8332,  9455,  2050, 17030,  1348,  5048, 14494,   102,\n",
      "             0],\n",
      "        [  101, 26600,  9455,  2050, 17030,  1348,  5048, 14494,   102,     0,\n",
      "             0],\n",
      "        [  101, 10496, 26600,  5048, 14494,   102,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  8331,  1107, 26600,  5048, 14494,   102,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])}, 'Pleural Effusion': {'input_ids': tensor([[  101,  1415,  1268, 20557,   185,  1513, 12602,   174,  3101, 17268,\n",
      "           102,     0,     0,     0],\n",
      "        [  101, 10558,  1268,  4841, 16091, 13505, 13207,   185,  1513, 12602,\n",
      "           174,  3101, 17268,   102],\n",
      "        [  101, 10558,  1286, 20557,   185,  1513, 12602,   174,  3101, 17268,\n",
      "           102,     0,     0,     0],\n",
      "        [  101, 10558,  1268, 20557,   185,  1513, 12602,   174,  3101, 17268,\n",
      "           102,     0,     0,     0],\n",
      "        [  101,  1353,  1286, 20557,   185,  1513, 12602,   174,  3101, 17268,\n",
      "           102,     0,     0,     0],\n",
      "        [  101,  6111,  1286, 20557,   185,  1513, 12602,   174,  3101, 17268,\n",
      "           102,     0,     0,     0],\n",
      "        [  101,  1415,  4296, 20557,   185,  1513, 12602,   174,  3101, 17268,\n",
      "           102,     0,     0,     0],\n",
      "        [  101,  1415,  1286, 20557,   185,  1513, 12602,   174,  3101, 17268,\n",
      "           102,     0,     0,     0],\n",
      "        [  101, 10558,  4296, 20557,   185,  1513, 12602,   174,  3101, 17268,\n",
      "           102,     0,     0,     0],\n",
      "        [  101,  1415,  1286,  4841, 16091, 13505, 13207,   185,  1513, 12602,\n",
      "           174,  3101, 17268,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}})}\n"
     ]
    }
   ],
   "source": [
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16d7238e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_values shape: torch.Size([1, 3, 224, 224])\n",
      "pixel_values shape: torch.Size([1, 3, 224, 224])\n",
      "pixel_values shape: torch.Size([1, 3, 224, 224])\n",
      "pixel_values shape: torch.Size([1, 3, 224, 224])\n",
      "pixel_values shape: torch.Size([1, 3, 224, 224])\n",
      "{'logits': tensor([[nan, nan, nan, nan, nan]], device='cuda:0', grad_fn=<StackBackward0>), 'class_names': ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']}\n"
     ]
    }
   ],
   "source": [
    "output = clf(**inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ff3175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
